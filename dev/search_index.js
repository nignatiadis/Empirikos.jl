var documenterSearchIndex = {"docs":
[{"location":"estimation/#Estimation","page":"Estimation","title":"Estimation","text":"","category":"section"},{"location":"estimation/#Convex-optimization","page":"Estimation","title":"Convex optimization","text":"","category":"section"},{"location":"estimation/","page":"Estimation","title":"Estimation","text":"NPMLE\nEmpirikos.KolmogorovSmirnovMinimumDistance","category":"page"},{"location":"estimation/#Empirikos.NPMLE","page":"Estimation","title":"Empirikos.NPMLE","text":"NPMLE(convexclass, solver)\n\nGiven n independent samples Z_i from the empirical Bayes problem with prior G known to lie in the convexclass mathcalG, estimate G by Nonparametric Maximum Likelihood (NPMLE)\n\nwidehatG_n in operatornameargmax_G in mathcalGsum_i=1^n log( f_iG(Z_i)) \n\nwhere f_iG(z) = int p_i(z mid mu) dG(mu) is the marginal density of the i-th sample.\n\n\n\n\n\n","category":"type"},{"location":"estimation/#Empirikos.KolmogorovSmirnovMinimumDistance","page":"Estimation","title":"Empirikos.KolmogorovSmirnovMinimumDistance","text":"KolmogorovSmirnovMinimumDistance(convexclass, solver)\n\nGiven n i.i.d. samples from the empirical Bayes problem with prior G known to lie in the convexclass mathcalG , estimate G as follows:\n\nwidehatG_n in operatornameargmin_G in mathcalGsup_t in mathbb Rlvert F_G(t) - widehatF_n(t)rvert\n\nwhere widehatF_n is the ECDF of the samples.\n\n\n\n\n\n","category":"type"},{"location":"samples/#EBayesSamples","page":"EBayesSamples","title":"EBayesSamples","text":"","category":"section"},{"location":"samples/","page":"EBayesSamples","title":"EBayesSamples","text":"The design choice of this package, is that each sample is wrapped in a type that represents its likelihood. This works well, since in the empirical Bayes problem, we typically impose (simple) assumptions on the distribution of Z_i mid mu_i and complexity emerges from making compound or nonparametric assumptions on the mu_i and sharing information across i. The main advantage is that it then makes it easy to add new likelihoods and have it automatically integrate with the rest of the package (say the nonparametric maximum likelihood estimator) through Julia's multiple dispatch. ","category":"page"},{"location":"samples/","page":"EBayesSamples","title":"EBayesSamples","text":"The abstract type is ","category":"page"},{"location":"samples/","page":"EBayesSamples","title":"EBayesSamples","text":"Empirikos.EBayesSample","category":"page"},{"location":"samples/#Empirikos.EBayesSample","page":"EBayesSamples","title":"Empirikos.EBayesSample","text":"EBayesSample{T}\n\nAbstract type representing empirical Bayes samples with realizations of type T.\n\n\n\n\n\n","category":"type"},{"location":"samples/#StandardNormalSample","page":"EBayesSamples","title":"StandardNormalSample","text":"","category":"section"},{"location":"samples/","page":"EBayesSamples","title":"EBayesSamples","text":"We explain the interface in the most well-studied empirical Bayes setting, namely the Gaussian compound decision problem wherein Z_i mid mu_i sim mathcalN(mu_i1).  Such a sample is represented through the StandardNormalSample type:","category":"page"},{"location":"samples/","page":"EBayesSamples","title":"EBayesSamples","text":"StandardNormalSample","category":"page"},{"location":"samples/#Empirikos.StandardNormalSample","page":"EBayesSamples","title":"Empirikos.StandardNormalSample","text":"StandardNormalSample(Z)\n\nAn observed sample Z drawn from a Normal distribution with known variance sigma^2 =1.\n\nZ sim mathcalN(mu 1)\n\nmu is assumed unknown. The type above is used when the sample Z is to be used for estimation or inference of mu.\n\nStandardNormalSample(0.5)          #Z=0.5\n\n\n\n\n\n","category":"type"},{"location":"samples/","page":"EBayesSamples","title":"EBayesSamples","text":"The type can be used in three ways. First, say we observe Z_i=10, then we reprent that as Z = StandardNormalSample(1.0).  Two more advanced functionalities consist of StandardNormalSample(missing), which represents the random variable Z_i without having observed its realization yet. Finally, StandardNormalSample(Interval(0.0,1.0)) represents a Z_i whose realization lies in 01; this is useful to conduct rigorous discretizations (that can speed up many estimation algorithms). We note that open, closed, unbounded intervals and so forth are allowed, cf. the intervals in the Intervals.jl package.","category":"page"},{"location":"samples/","page":"EBayesSamples","title":"EBayesSamples","text":"The main interface functions are the following:","category":"page"},{"location":"samples/","page":"EBayesSamples","title":"EBayesSamples","text":"likelihood_distribution\nresponse\nmarginalize","category":"page"},{"location":"samples/#Empirikos.likelihood_distribution","page":"EBayesSamples","title":"Empirikos.likelihood_distribution","text":"likelihood_distribution(Z::EBayesSample, μ::Number)\n\nReturns the distribution p(cdot mid mu) of Z mid mu (the return type being Distributions.jl Distribution).\n\nExamples\n\njulia> likelihood_distribution(StandardNormalSample(1.0), 2.0)\nNormal{Float64}(μ=2.0, σ=1.0)\n\n\n\n\n\n","category":"function"},{"location":"samples/#StatsBase.response","page":"EBayesSamples","title":"StatsBase.response","text":"response(Z::EBayesSample{T})\n\nReturns the concrete realization of Z as type T, thus dropping the information about the likelihood.\n\nExamples\n\njulia> response(StandardNormalSample(1.0))\n1.0\n\n\n\n\n\n","category":"function"},{"location":"samples/#Empirikos.marginalize","page":"EBayesSamples","title":"Empirikos.marginalize","text":"marginalize(Z::EBayesSample, prior::Distribution)\n\nGiven a prior distribution G and  EBayesSample Z, return that marginal distribution of Z. Works for EBayesSample{Missing}, i.e., no realization is needed.\n\nExamples\n\njulia-repl julia> marginalize(StandardNormalSample(1.0), Normal(2.0, sqrt(3))) Normal{Float64}(μ=2.0, σ=1.9999999999999998)`\n\n\n\n\n\n","category":"function"},{"location":"samples/#Available-EBayes-sample-types","page":"EBayesSamples","title":"Available EBayes sample types","text":"","category":"section"},{"location":"samples/","page":"EBayesSamples","title":"EBayesSamples","text":"Currently, the following samples have been implemented.","category":"page"},{"location":"samples/","page":"EBayesSamples","title":"EBayesSamples","text":"NormalSample\nBinomialSample\nPoissonSample","category":"page"},{"location":"samples/#Empirikos.NormalSample","page":"EBayesSamples","title":"Empirikos.NormalSample","text":"NormalSample(Z,σ)\n\nAn observed sample Z drawn from a Normal distribution with known variance sigma^2  0.\n\nZ sim mathcalN(mu sigma^2)\n\nmu is assumed unknown. The type above is used when the sample Z is to be used for estimation or inference of mu.\n\nNormalSample(0.5, 1.0)          #Z=0.5, σ=1\n\n\n\n\n\n","category":"type"},{"location":"samples/#Empirikos.BinomialSample","page":"EBayesSamples","title":"Empirikos.BinomialSample","text":"BinomialSample(Z, n)\n\nAn observed sample Z drawn from a Binomial distribution with n trials.\n\nZ sim textBinomial(n p)\n\np is assumed unknown. The type above is used when the sample Z is to be used for estimation or inference of p.\n\nBinomialSample(2, 10)          # 2 out of 10 trials successful\n\n\n\n\n\n","category":"type"},{"location":"samples/#Empirikos.PoissonSample","page":"EBayesSamples","title":"Empirikos.PoissonSample","text":"PoissonSample(Z, E)\n\nAn observed sample Z drawn from a Poisson distribution,\n\nZ sim textPoisson(mu cdot E)\n\nThe multiplying intensity E is assumed to be known (and equal to 1.0 by default), while mu is assumed unknown. The type above is used when the sample Z is to be used for estimation or inference of mu.\n\nPoissonSample(3)\nPoissonSample(3, 1.5)\n\n\n\n\n\n","category":"type"},{"location":"#Empirikos.jl","page":"Empirikos.jl","title":"Empirikos.jl","text":"","category":"section"},{"location":"","page":"Empirikos.jl","title":"Empirikos.jl","text":"Consider n independent samples Z_i drawn from the following hierarchical model","category":"page"},{"location":"","page":"Empirikos.jl","title":"Empirikos.jl","text":"mu_i sim G   Z_i sim p_i(cdot mid mu)","category":"page"},{"location":"","page":"Empirikos.jl","title":"Empirikos.jl","text":"Here G is the unknown prior (effect size distribution) and p_i(cdot mid mu)i=1dotscn are known likelihood functions.","category":"page"},{"location":"","page":"Empirikos.jl","title":"Empirikos.jl","text":"This package provides a unified framework for estimation and inference under the above setting, which is known as the empirical Bayes problem [Herbert Robbins  (1956)].","category":"page"},{"location":"","page":"Empirikos.jl","title":"Empirikos.jl","text":"note: Modularity\nThe package here has been designed with the goal of modularity.    Specialized code (using Julia's multiple dispatch) handles different combinations of estimation targets, statistical algorithms, classes of priors and likelihoods. Please open an issue if there is a combination thereof that you would like to use (and which does not work currently).","category":"page"},{"location":"#Installation","page":"Empirikos.jl","title":"Installation","text":"","category":"section"},{"location":"","page":"Empirikos.jl","title":"Empirikos.jl","text":"The package is available from the Julia registry. It may be installed as follows:","category":"page"},{"location":"","page":"Empirikos.jl","title":"Empirikos.jl","text":"using Pkg\nPkg.add(\"Empirikos\")","category":"page"},{"location":"#Related-packages-in-R","page":"Empirikos.jl","title":"Related packages in R","text":"","category":"section"},{"location":"","page":"Empirikos.jl","title":"Empirikos.jl","text":"REBayes  [Roger Koenker , Jiaying Gu  (2017)]. A partial reproduction of the REBayes vignette with Empirikos.jl is available here.\nAshr  [Matthew Stephens  (2016)]\nDeconvolveR  [Balasubramanian Narasimhan , Bradley Efron  (2020)]\nEbayesThresh  [Iain M Johnstone , Bernard W Silverman  (2005)]","category":"page"},{"location":"#References","page":"Empirikos.jl","title":"References","text":"","category":"section"},{"location":"","page":"Empirikos.jl","title":"Empirikos.jl","text":"","category":"page"},{"location":"neighborhoods/#Neighborhoods","page":"Neighborhoods","title":"Neighborhoods","text":"","category":"section"},{"location":"neighborhoods/","page":"Neighborhoods","title":"Neighborhoods","text":"DvoretzkyKieferWolfowitz","category":"page"},{"location":"neighborhoods/#Empirikos.DvoretzkyKieferWolfowitz","page":"Neighborhoods","title":"Empirikos.DvoretzkyKieferWolfowitz","text":"DvoretzkyKieferWolfowitz(α) <: EBayesNeighborhood\n\nThe Dvoretzky-Kiefer-Wolfowitz band (based on the Kolmogorov-Smirnov distance) at confidence level 1-α that bounds the distance of the true distribution function to the ECDF widehatF_n based on n samples. The constant of the band is the sharp constant derived by Massart:\n\nF text distribution  sup_t in mathbb Rlvert F(t) - widehatF_n(t) rvert  leq  sqrtlog(2alpha)(2n)\n\n\n\n\n\n","category":"type"},{"location":"neighborhoods/","page":"Neighborhoods","title":"Neighborhoods","text":"ChiSquaredNeighborhood","category":"page"},{"location":"neighborhoods/#Empirikos.ChiSquaredNeighborhood","page":"Neighborhoods","title":"Empirikos.ChiSquaredNeighborhood","text":"ChiSquaredNeighborhood(α) <: EBayesNeighborhood\n\nThe chi^2 neighborhood at confidence level 1-alpha for a discrete random variable taking values in 0dotsc N. It is equal to:\n\nf sum_x=0^N frac(n hatf_n(x) - n f(x))^2n f(x) leq chi^2_N1-alpha\n\nwhere chi^2_N1-alpha is the 1-alpha quantile of the Chi-squared distribution with N degrees of freedom, n is the sample size, hatf_n(x) is the proportion of samples equal to x and f(x) is then population pmf.\n\n\n\n\n\n","category":"type"}]
}
